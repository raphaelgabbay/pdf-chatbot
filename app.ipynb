{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3f1cba",
   "metadata": {},
   "source": [
    "# PDF Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d1b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script filetype.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wsdump.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pybase64.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pyproject-build.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script watchfiles.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script chroma.exe is installed in 'c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: c:\\Users\\rafro\\.pyenv\\pyenv-win\\versions\\3.10.11\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r \"./requirements.txt\" -q # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef018f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aab90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2, os, csv\n",
    "import streamlit as st\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15b074",
   "metadata": {},
   "source": [
    "\n",
    "## get_pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44bfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    full_text = \"\"\n",
    "    for doc in pdf_docs:\n",
    "        with open(doc, 'rb') as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "            for page in reader.pages:\n",
    "                full_text += \" \"\n",
    "                full_text += page.extract_text()\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be87aa8",
   "metadata": {},
   "source": [
    "## get_text_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b7954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=10000,\n",
    "        chunk_overlap=1000\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks  # list of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a3d54",
   "metadata": {},
   "source": [
    "## get_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f4c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d82843",
   "metadata": {},
   "source": [
    "## Build the Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d58e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain():\n",
    "    prompt_template = \"\"\"\n",
    "    Question : {question}\n",
    "    Answer as detailed as possible based on the given context and answer “answer is not available in the context” if the answer is not in the context.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n",
    "                                   client = None,\n",
    "                                   temperature=0.3,\n",
    "                                   )\n",
    "    prompt = PromptTemplate(template=prompt_template,\n",
    "                            input_variables=\"question\")\n",
    "    chain = load_qa_chain(llm=model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89891c24",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1d4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"TODO\")  # type: ignore\n",
    "\n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True) \n",
    "    docs = new_db.similarity_search(user_question)\n",
    "\n",
    "    chain = get_conversational_chain()\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    response = chain(\n",
    "        {\"input_documents\": docs, \"context\": context, \"question\": user_question}, return_only_outputs=True, )\n",
    "\n",
    "    return response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32383712",
   "metadata": {},
   "source": [
    "## save_user_info(name, phone, email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d2b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_user_info(name, phone, email):\n",
    "    file_exists = os.path.isfile('user_info.csv')\n",
    "    with open('user_info.csv', mode='a', newline='') as file:\n",
    "        if not file_exists:\n",
    "            file = open('myfile.dat', 'w+')\n",
    "        fieldnames = ['Name', 'Phone', 'Email']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writerow({'Name': name, 'Phone': phone, 'Email': email})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed0d0e",
   "metadata": {},
   "source": [
    "## Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15945c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():  \n",
    "    st.set_page_config(  # Configure the Streamlit page settings\n",
    "        page_title=\"PDF Chatbot\",  # Set the browser tab title\n",
    "        # page_icon=\"TODO\",  # Set the favicon/icon for the page\n",
    "        layout=\"wide\" # Use a wide layout for more horizontal space\n",
    "    ) \n",
    "\n",
    "    # Sidebar for uploading PDF files\n",
    "    with st.sidebar:  # Begin sidebar container\n",
    "        st.sidebar.title(\"Menu\")  # Display the title \"Menu\" in the sidebar\n",
    "        pdf_docs = st.file_uploader(  # file uploader widget\n",
    "            \"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)  # Allow multiple PDF uploads\n",
    "        submitBtn = st.button(\"Submit & Process\")\n",
    "        if \"submitBtn\" not in st.session_state:\n",
    "            st.session_state.submitBtn_state = False:  # Add a button \"Submit & Process\" to trigger processing\n",
    "            \n",
    "            with TODO:  # Show a spinner while processing\n",
    "                raw_text = get_pdf_text(pdf_docs)  # Extract raw text from uploaded PDFs\n",
    "                text_chunks = get_text_chunks(raw_text)  # Split the text into smaller chunks\n",
    "                get_vector_store(text_chunks)  # Build or update vector store for retrieval\n",
    "                st.success(\"Done\")  # Show a success message once processing finishes\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
